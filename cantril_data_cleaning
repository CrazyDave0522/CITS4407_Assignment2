#!/bin/bash

# Author: Zixiao Ma (24116864)
# Created Date: 17 May 2024
# GitHub Link: https://github.com/CrazyDave0522/CITS4407_Assignment2

# Description
## This script is designed to clean the data based on certain rules (see below).

# Input: This script expects three .tsv files,
## which are `gdp-vs-happiness.tsv`, `homicide-rate-unodc.tsv`, `life-satisfaction-vs-life-expectancy.tsv`.
## The input files may be in any order.

# Output: A tab-separated data directed to standard output.
## Based on the header line, make sure that the file is a tab-separated format file
## Also based on the header line, report any lines that do not have the same number of cells. (Cells are allowed to be empty.)
## Remove the column with header `Continent`.
## Ignore the rows where the country code field is empty.
## Only keep the rows with years from 2011 to 2021, inclusive.
## The output file sent to stdout has rows with the data in the following order (tab separated):
## <Entity> <Code> <Year> <GDP per capita> <Population> <Homicide Rate> <Life Expectancy> <Cantril Ladder score>


# Function to check if a file is tab-separated
# and has a consistent number of cells per row
check_file() {
    local file=$1
    local header=$(head -n 1 "$file")
    local num_columns=$(echo "$header" | awk -F'\t' '{print NF}')
    local line_num=1

    while IFS= read -r line; do
        local num_cells=$(echo "$line" | awk -F'\t' '{print NF}')
        if [[ $num_cells -ne $num_columns ]]; then
            echo "Warning: Line $line_num in $file does not have $num_columns cells." >&2
        fi
        ((line_num++))
    done <"$file"
}

# Function to remove the "Continent" column from the file
remove_continent_column() {
    local file=$1
    awk -F'\t' '
        {
            # Print each row excluding the 7th column (Continent),
            # since the order of the columns will not change
            for (i = 1; i <= NF; i++) {
                if (i != 7) {
                    printf "%s", $i
                    if (i < NF && i != 6) {
                        printf "\t"
                    }
                }
            }
            printf "\n"
        }
    ' OFS='\t' "$file"
}

# Function to remove rows where the country code field is empty
remove_empty_country_code() {
    local file=$1
    awk -F'\t' '
        NR==1 {
            # Print header
            print $0
        }
        NR > 1 {
            # Only include rows with non-empty country code
            if ($2 != "") {
                print $0
            }
        }
    ' OFS='\t' "$file"
}

# Function to filter rows by the year range (2011-2021)
filter_by_year() {
    local file=$1
    awk -F'\t' '
        NR==1 {
            # Print header
            print $0
        }
        NR > 1 {
            # Only include rows with years 2011-2021
            if ($3 >= 2011 && $3 <= 2021) {
                print $0
            }
        }
    ' OFS='\t' "$file"
}

# Function to sort the data based on
# the combination of the second(code) and third(year) column
sort_data() {
    {
        read -r header
        echo "$header"
        sort -t $'\t' -k2,2 -k3,3n
    }
}

# Main Script
## Input check
### Check if the correct number of arguments is provided
if [[ "$#" -ne 3 ]]; then
    echo "Usage: $0 gdp-vs-happiness.tsv homicide-rate-unodc.tsv life-satisfaction-vs-life-expectancy.tsv" >&2
    exit 1
fi

### Check if the data files exist
for file in "$1" "$2" "$3"; do
    if [[ ! -s "$file" ]]; then
        echo "The input file $file does not exist or has zero length" >&2
        exit 1
    fi
done

# Check each file
for file in "$@"; do
    check_file "$file"
done

# Determine the order of files and assign them to variables
for file in "$@"; do
    case "$file" in
    *gdp-vs-happiness.tsv)
        gdp_happiness="$file"
        ;;
    *homicide-rate-unodc.tsv)
        homicide_rate="$file"
        ;;
    *life-satisfaction-vs-life-expectancy.tsv)
        life_satisfaction="$file"
        ;;
    *)
        echo "Unexpected file: $file" >&2
        exit 1
        ;;
    esac
done

# Process and store cleaned data into variables
gdp_happiness_cleaned=$(remove_continent_column "$gdp_happiness" | remove_empty_country_code | filter_by_year | sort_data)
homicide_rate_cleaned=$(remove_continent_column "$homicide_rate" | remove_empty_country_code | filter_by_year | sort_data)
life_satisfaction_cleaned=$(remove_continent_column "$life_satisfaction" | remove_empty_country_code | filter_by_year | sort_data)

# Merging the data files
# Step 1: Define a new variable merged_data, merged_data=gdp_happiness_cleaned
merged_data=$(echo "$gdp_happiness_cleaned")

# Step 2: Add a column in merged_data, header is "Homicide Rate", cells are empty
header=$(echo "$merged_data" | head -n 1)
header="$header\tHomicide Rate"
merged_data=$(echo "$merged_data" | awk -v header="$header" 'NR==1{print header; next} {print $0 "\t"}')

# Step 3: Fill "Homicide Rate" column based on homicide_rate_cleaned
while IFS= read -r line; do
    code=$(echo "$line" | awk -F'\t' '{print $2}')
    year=$(echo "$line" | awk -F'\t' '{print $3}')
    rate=$(echo "$line" | awk -F'\t' '{print $4}')
    merged_data=$(echo "$merged_data" | awk -v code="$code" -v year="$year" -v rate="$rate" -F'\t' 'BEGIN{OFS=FS} NR==1{print $0; next} $2==code && $3==year{$NF=rate} {print $0}')
done < <(echo "$homicide_rate_cleaned" | tail -n +2)

# Step 4: Add a column in merged_data, header is "Life Expectancy", cells are empty
header=$(echo "$merged_data" | head -n 1)
header="$header\tLife Expectancy"
merged_data=$(echo "$merged_data" | awk -v header="$header" 'NR==1{print header; next} {print $0 "\t"}')

# Step 5: Fill "Life Expectancy" column based on life_satisfaction_cleaned
while IFS= read -r line; do
    code=$(echo "$line" | awk -F'\t' '{print $2}')
    year=$(echo "$line" | awk -F'\t' '{print $3}')
    expectancy=$(echo "$line" | awk -F'\t' '{print $4}')
    merged_data=$(echo "$merged_data" | awk -v code="$code" -v year="$year" -v expectancy="$expectancy" -F'\t' 'BEGIN{OFS=FS} NR==1{print $0; next} $2==code && $3==year{$NF=expectancy} {print $0}')
done < <(echo "$life_satisfaction_cleaned" | tail -n +2)

# Gerneral Process
# Change the name of the fifth and sixth header to "GDP per capita" and "Population"
merged_data=$(echo "$merged_data" | awk -F'\t' 'NR==1{$5="GDP per capita"; $6="Population"; print; next} {print}' OFS='\t')
# Adjust the order of columns in merged_data
merged_data=$(echo "$merged_data" | awk -F'\t' 'NR==1{print $1, $2, $3, $5, $6, $7, $8, $4; next} {print $1, $2, $3, $5, $6, $7, $8, $4}' OFS='\t')

# Output the final merged data to stdout
echo "$merged_data"
